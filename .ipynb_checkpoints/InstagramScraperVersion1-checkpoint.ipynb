{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import choice\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import datetime\n",
    " \n",
    "_user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'\n",
    "]\n",
    " \n",
    "def get_nested(data, *args): #Recursive function to get nested json params\n",
    "    if args and data:\n",
    "        element  = args[0]\n",
    "        if element:\n",
    "            value = data.get(element)\n",
    "            return value if len(args) == 1 else get_nested(value, *args[1:])   \n",
    "     \n",
    " \n",
    "class InstagramScraper:\n",
    " \n",
    "    def __init__(self, user_agents=None, proxy=None):\n",
    "        self.user_agents = user_agents\n",
    "        self.proxy = proxy\n",
    " \n",
    "    def __random_agent(self):\n",
    "        if self.user_agents and isinstance(self.user_agents, list):\n",
    "            return choice(self.user_agents)\n",
    "        return choice(_user_agents)\n",
    " \n",
    "    def __request_url(self, url):\n",
    "        try:\n",
    "            response = requests.get(url, headers={'User-Agent': self.__random_agent()}, proxies={'http': self.proxy,\n",
    "                                                                                                 'https': self.proxy})\n",
    "            print(response)\n",
    "            response.raise_for_status()\n",
    "        except requests.HTTPError:\n",
    "            raise requests.HTTPError('Received non 200 status code from Instagram')\n",
    "        except requests.RequestException:\n",
    "            raise requests.RequestException\n",
    "        else:\n",
    "            return response.text\n",
    "        \n",
    "   \n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_json_data(html):\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        body = soup.find('body')\n",
    "        script_tag = body.find('script')\n",
    "        raw_string = script_tag.text.strip().replace('window._sharedData =', '').replace(';', '')\n",
    "        return json.loads(raw_string)\n",
    " \n",
    "    def profile_page_metrics(self, profile_url):\n",
    "        if not os.path.exists(\"InstagramProject/InstagramImages/\"+profile_url):\n",
    "            os.makedirs(\"InstagramProject/InstagramImages/\"+profile_url) #create path for images\n",
    "        ig_url = 'https://www.instagram.com/'+profile_url\n",
    "        results = {}\n",
    "        try:\n",
    "            response = self.__request_url(ig_url)\n",
    "            json_data = self.extract_json_data(response)\n",
    "            metrics = json_data['entry_data']['ProfilePage'][0]['graphql']['user']\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        else:\n",
    "            for key, value in metrics.items():\n",
    "                    if value and isinstance(value, dict):\n",
    "                        value = value['count']\n",
    "                        results[key] = value\n",
    "                    else: #value:\n",
    "                        results[key] = value\n",
    "\n",
    "        urllib.request.urlretrieve(results['profile_pic_url'],'InstagramProject/InstagramImages/'+profile_url+'/profile.jpg') #save all images    \n",
    "        return results\n",
    "\n",
    "        \n",
    "   \n",
    "    def profile_page_recent_posts(self, profile_url):\n",
    "        ig_url = 'https://www.instagram.com/'+profile_url\n",
    "\n",
    "        big_results = []  \n",
    "        i=1\n",
    "        try:\n",
    "            response = self.__request_url(ig_url)\n",
    "            json_data = self.extract_json_data(response)\n",
    "            metrics = json_data['entry_data']['ProfilePage'][0]['graphql']['user']['edge_owner_to_timeline_media'][\"edges\"]\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        else:\n",
    "            for node in metrics:\n",
    "                \n",
    "                results = {}\n",
    "                node = node.get('node')\n",
    "                for key, value in node.items():\n",
    "                    if value and isinstance(value, dict):\n",
    "                        if key == 'edge_media_to_caption':\n",
    "                            temp = get_nested(value, \"edges\")\n",
    "                            results[key] = get_nested(temp[0],\"node\", \"text\")\n",
    "                        elif key == 'edge_media_to_comment':\n",
    "                            results[key] = value['count']\n",
    "                        elif key == 'edge_liked_by':\n",
    "                            results[key] = value['count']\n",
    "                        elif key == 'edge_media_preview_like':\n",
    "                            results[key] = value['count'] \n",
    "                        elif key == 'location':\n",
    "                            results[key] = value['name']\n",
    "                        else:\n",
    "                            results[key] = value\n",
    "                    else:\n",
    "                        results[key] = value\n",
    "                urllib.request.urlretrieve(node['display_url'],'InstagramProject/InstagramImages/'+profile_url+'/%i.jpg'%i)    \n",
    "                i+=1\n",
    "                big_results.append(results)\n",
    "        \n",
    "        return big_results\n",
    "    \n",
    "    def createProfileData(self, profile_url): #function to create json for user\n",
    "        pageResults = self.profile_page_metrics(profile_url)\n",
    "        postResults = self.profile_page_recent_posts(profile_url)\n",
    "        print(postResults)\n",
    "        pageResults['posts']=postResults\n",
    "        with open('InstagramProject/UserData/'+profile_url+'.json', 'w', encoding=\"utf-8\") as f:\n",
    "          json.dump(pageResults, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Path = \"InstagramProject/UserData/\"\n",
    "filelist = []\n",
    "for file in os.listdir(Path): #create filelist with all user json files\n",
    "    if file.endswith(\".json\"):\n",
    "        filelist.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "firstPostDone=0\n",
    "firstUserDone=0\n",
    "\n",
    "profileColumns = ['biography', 'business_category_name', 'connected_fb_page', 'country_block', 'edge_felix_video_timeline', 'edge_follow', 'edge_followed_by', 'edge_media_collections','edge_owner_to_timeline_media','edge_saved_media','external_url','external_url_linkshimmed','full_name','has_channel','highlight_reel_count', 'id','is_business_account','is_joined_recently','is_private','is_verified', 'profile_pic_url', 'profile_pic_url_hd', 'username'] \n",
    "postColumns = ['accessibility_caption', 'comments_disabled', 'edge_liked_by', 'display_url', 'edge_media_preview_like', 'edge_media_to_caption', 'edge_media_to_comment', 'is_video', 'location', 'taken_at_timestamp', 'hashtags', 'mentions','time_between','number_of_likes/mean', 'number_of_likes/median']   \n",
    "for k in filelist:\n",
    "    with open(Path + str(k), encoding=\"utf-8\") as json_data:\n",
    "        data = json.load(json_data) #open file\n",
    "\n",
    "\n",
    "        profileData=dict((k, data[k]) for k in profileColumns if k in data) #create dict from json\n",
    "        profileDF=pd.DataFrame.from_dict(profileData, orient='index').T  #create dataframe\n",
    "\n",
    "        postData = data['posts']\n",
    "        for i in range(0,len(postData)): #run for all posts\n",
    "            for k in postColumns:\n",
    "                if k in postData[i]:\n",
    "                    if isinstance(postData[i][k], str):\n",
    "                        postData[i][k]=postData[i][k].replace('\\n','')\n",
    "                else:\n",
    "                    postData[i][k] = \"None\"\n",
    "                if k == 'edge_media_to_caption':\n",
    "                    postData[i][\"hashtags\"] = [i[1:] for i in postData[i][k].split() if i.startswith(\"#\")] #create hashtag field\n",
    "                    postData[i][\"mentions\"] = [i[1:] for i in postData[i][k].split() if i.startswith(\"@\")] #create mentions field  \n",
    "            post = dict((k, postData[i][k]) for k in postColumns if k in postData[i])\n",
    "            \n",
    "            if (firstPostDone == 0):\n",
    "                totalPosts = np.hstack((profileDF, pd.DataFrame.from_dict(post, orient='index').T))\n",
    "                firstPostDone=1\n",
    "            else:\n",
    "                nextPost = np.hstack((profileDF, pd.DataFrame.from_dict(post, orient='index').T))\n",
    "                totalPosts = np.vstack((totalPosts,nextPost)) \n",
    "\n",
    "        intermediateDF=pd.DataFrame(totalPosts, columns=list((profileColumns))+list((postColumns)))\n",
    "        intermediateDF['time_between'] = intermediateDF['taken_at_timestamp'] - intermediateDF['taken_at_timestamp'].shift(-1)\n",
    "        intermediateDF['time_between'].fillna((intermediateDF['time_between'].mean()), inplace=True)\n",
    "        intermediateDF['number_of_likes/mean'] = intermediateDF['edge_liked_by'].divide(intermediateDF['edge_liked_by'].mean())\n",
    "        intermediateDF['number_of_likes/median'] = intermediateDF['edge_liked_by'].divide(intermediateDF['edge_liked_by'].median())\n",
    "                     \n",
    "        if (firstUserDone == 0):\n",
    "            aggregateData = intermediateDF\n",
    "            firstUserDone=1\n",
    "        else:\n",
    "            aggregateData=np.vstack((aggregateData,pd.DataFrame(intermediateDF, columns=list((profileColumns))+list((postColumns)))))          \n",
    "        firstPostDone=0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "InstagramDataset=pd.DataFrame(aggregateData, columns=profileColumns+postColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "InstagramDataset['day'] = InstagramDataset['taken_at_timestamp'].apply(lambda x: (datetime.datetime.fromtimestamp(x)).strftime('%A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "data1_dummy = pd.get_dummies(InstagramDataset[\"day\"])\n",
    "InstagramDataset = InstagramDataset.join(data1_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "InstagramDataset['hour_of_day'] = InstagramDataset['taken_at_timestamp'].apply(lambda x: int((datetime.datetime.fromtimestamp(x)).strftime('%H')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "InstagramDataset['hr_sin'] = np.sin(InstagramDataset.hour_of_day*(2.*np.pi/24))\n",
    "InstagramDataset['hr_cos'] = np.cos(InstagramDataset.hour_of_day*(2.*np.pi/24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = [0, 4, 8, 12, 16, 20, 24]\n",
    "InstagramDataset['HourBin'] = pd.cut(InstagramDataset['hour_of_day'], bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "InstagramDataset['HourBin_Code'] = label.fit_transform(InstagramDataset['HourBin'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
